# coding=utf-8
import scrapy
import pymongo
from doubanspider.items import BookinfoItem
import re
from bs4 import BeautifulSoup
import time

max_page = 200


# 思路：获取豆瓣图书的top250页面的每本书的id
# --------------------------------------------------------------------------------------------------------------------------------------------------------------------------

class MyDoubanSpider(scrapy.Spider):
    name = 'bookid'

    def start_requests(self):
        page = 0
        # all_books = [26376049,26354440,26431326,20441569,26602467,26298832,1552067,3090810,26613940,26586326,21329239,3206270,26612656,2180619,3537590,26369400,1051314,2758522,1679427,25791940,26289614,22741515,26413619,3023514,1025217,6742607,1089662,1963579,2337526,6900434,2020973,2058587,26612175,26582467,5936256,4711072,2050776,1038241,1042928,26308765,26576301,5299857,4145391,5447429,5291316,1227902,1281180,1058094,4152770,26609559,25795816,24845288,1702664,2210591,26667893,26575912,4063155,22606931,5264480,4934765,26433353,25900687,26611925,26667196,26594136,10435653,26435048,26657701,25810430,25795767,24722098,26652938,26575906,26646483,1456987,26339094,1538532,6821265,1469400,2281786,2246675,3824491,1016454,26253243,1420931,6745115,3149816,6999547,2967922,1898229,2216345,3063476,21263656,20481425,26629399,4191879,3633809,2188017,25703706,3575882,4173398,6798785,24745626,1019945,1006732,26369112,1418345,25843885,4038653,3035211,1450049,25761048,1690499,6151925,7058037,26325343,6798784,1841628,2023303,10825075,3664005,4861161,10484660,2137736,1119635,26390925,20371005,3275016,1426482,3200737,6744666,4208024,1069507,6783954,1864292,5989231,4162721,6848987,26576988,1358352,1312942,24527472,24529918,6012778,5326853,10563199,3300769,1761133,26413771,1562802,1860524,1264559,1317916,1317858,1732246,4214003,2170091,3434743,1980834,5326323,26598392,10518802,1770271,26388038,2156890,5318879,3397116,3271909,3529625,1059588,6451549,26370029,26368750,5380385,1014107,1084607,1063612,4903219,2367967,1810540,4882046,1320971,10594804,3336952,25790419,5355500,26411827,25755526,2047854,1439509,4208659,2297005,25966878,1434471,3219205,3309340,1083265,1475583,2146204,1148767,3882007,24733665,10770529,16146169,1317861,1012268,1843305,1886273,1780173,3703389,24855142,2183857,25845259,4224723,10556798,10789137,26469434,1393269,1826176,3150203,25968143,1214078,2337485,1885360,6777734,10741325,25885817,25890145,10583781,3610090,4189598,2282097,2140283,4075203,1396491,26577705,1007313,1125731,2254615,26582109,26593255,1085168,11531722,7153413,1059473,3329793,2332766,25743736,1889166,11540911,20505732,3297535,2036622,1033949,25906751,1309257,25732175,2701313,3091416,2150077,1987958,4746569,1864645,26394511,1409381,10345574,1064359,1063627,1007918,20506307,21347632,10811150,2127477,3767767,7060213,20269358,26295466,25846881,2069650,6390078,1002685,3287536,22994269,23709956,5263671,26429537,1826198,1769992,5345300,19964281,1031102,25804600,2015137,3419882,2075156,23038645,25779226,24745120,2043893,1313423,1033071,10772478,2333097,5406398,3410753,2371893,10557523,1401851,4838087,3283630,25977265,1054088,1976072,1290598,5327987,1067229,2046828,1810525,24661794,4177153,24695948,2473821,20397030,1768892,1146381,1277314,25771895,1987990,26377842,25804639,6839928,1436076,25865673,25838973,24846148,10436182,3659826,3149831,3449736,26278718,3114172,1045492,1048353,2269445,4039101,10435423,3591511,2005566,25955897,26288256,25909800,6386365,1170854,4723764,4861166,26107457,3241978,6313251,2301586,1943535,1975142,1313421,5407560,25855959,3420483,3138950,3651090,3909892,26173346,24745090,26262687,2343046,2047253,2160115,4893032,1440246,25698245,6511197,26311206,1059491,3177616,2893580,3044263,3827061,25805746,26286860,1409382,6711750,2037622,20444987,25871639,1042434,4250782,1780277,6440022,26293794,25751980,26582466,20440053,26378094,26264973,6724865,26435042,3880774,26593737,26279332,1580554,26647868,4861163,1694151,2343043,3598390,3666293,1145077,4909239,6424714,6793917,4132677,10586570,25998328,1006784,25841449,1135343,1317929,1023119,2004387,1423412,3228470,26296571,10749372,6762965,19971983,26304728,26368754,6878906,4124468,1145074,3705794,1396390,2568280,6920074,10587458,3673614,3103742,26387803,1430596,25941616,3157873,10549874,1129442,4879355,5299374,26443792,1425910,1011067,1186026,2205639,1262371,24858421,1867075,21263655,25718213,26578531,24855184,2279358,24869701,6797768,1322401,26476909,6854919,26293216,25982110,5376976,5033915,2245468,24851444,1270508,24550625,4219120,1000531,26449219,1283292,1201259,24396667,26579664,1530882,2229229,4827423,3418938,1919879,4836821,19977771,1041893,25763658,1467776,20412218,25723401,1432045,26390172,4104794,5922151,4067659,26435047,5349406,6788196,4097167,3024665,19971138,26608445,4753689]  # 存所有书的id，以逗号分隔
        all_books = [10519369]
        url = 'https://book.douban.com/top250?start={}'.format(page)
        yield scrapy.Request(url=url, headers={'user-agent': 'Mozilla/5.0'}, meta={'page': page})

    def parse(self, response):
        soup = BeautifulSoup(response.body, 'html.parser')
        # 匹配以https://book.douban.com/subject/开头 并且title是中文的元素
        # a href="https://book.douban.com/subject/1770782/" onclick=&#34;moreurl(this,{i:&#39;0&#39;})&#34; title="（需要）"
        # ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
        books = soup.find_all('a', {'href': re.compile(r'^https://book.douban.com/subject/'), 'title': re.compile(u'[\u4e00-\u9fa5]')})
        # print books
        for book in books:
            item = BookinfoItem()
            # print book
            item['bookid'] = book.attrs['href']
            item['bookname'] = book.attrs['title']
            print item['bookid'], item['bookname']


        print len(books)

        if response.meta['page'] < max_page:
            page = response.meta['page'] + 1*25
            url = 'https://book.douban.com/top250?start={}'.format(page)
            print 'page:', page
            yield scrapy.Request(url=url, headers={'user-agent': 'Mozilla/5.0'}, meta={ 'page': page})

